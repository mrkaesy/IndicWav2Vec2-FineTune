
# ðŸ”Š IndicWav2Vec2Â â€” Endâ€‘toâ€‘End Fineâ€‘Tuning Guide (Hindi ASR)
> **Goal:** take raw Hindi audio + transcripts âžœ produce a stateâ€‘ofâ€‘theâ€‘art Automatic Speech Recognition (ASR) model using the **IndicWav2Vec2 Base** checkpoint.

---

## 0Â Â·Â Why This Guide Exists
Most academic READMEs assume you already know:
* what *manifest files* are,
* how to convert MP3 â†’ WAV,
* what `fairseq-hydra-train` even doesâ€¦

**This document is written for absolute newcomers** who want to reproduce our results from scratch on **any Linux box with â‰¥1â€¯GPU**.

---

## 1Â Â·Â Project Layout at a Glance

```
indicwav2vec_finetune/
â”œâ”€â”€ data_prep_scripts/        # All audioâ€‘processing helpers (download, VAD, SNRâ€¦)
â”‚   â”œâ”€â”€ dw_util.sh
â”‚   â”œâ”€â”€ vad.py
â”‚   â”œâ”€â”€ snr_filter.py
â”‚   â”œâ”€â”€ chunking.py
â”‚   â”œâ”€â”€ process_data.sh
â”‚   â””â”€â”€ lang_wise_manifest_creation.py
â”œâ”€â”€ configs/                  # Preâ€‘made Hydra configs for preâ€‘training
â”œâ”€â”€ finetune_configs/         # Hydra configs for fineâ€‘tuning
â”œâ”€â”€ lm_training/              # KenLM installation + training scripts
â”œâ”€â”€ w2v_inference/            # Inference / evaluation helpers
â”œâ”€â”€ reports/                  # PDF reports (midâ€‘term, final)
â””â”€â”€ README_ULTIMATE.md        # â† **YOU ARE HERE**
```

> **Tip:** keep this repo at `~/indicwav2vec_finetune` so the paths below match exactly.

---

## 2Â Â·Â Prerequisites

| Software            | Version (tested)      | Install command |
|---------------------|-----------------------|-----------------|
| Ubuntu              | 20.04Â LTS             | â€” |
| CUDAÂ Toolkit        | 11.7                  | see NVIDIA docs |
| Conda (Miniconda)   | â‰¥23.x                 | <https://conda.io> |
| Git                 | 2.34+                 | `sudo apt install git` |

### 2.1Â Create and Activate Environment

```bash
conda create -n wav2vec-finetune python=3.9 -y
conda activate wav2vec-finetune
```

### 2.2Â System Packages (audio libs, BLAS, etc.)

```bash
sudo apt-get update
sudo apt-get install -y libsndfile1-dev ffmpeg      liblzma-dev libbz2-dev libzstd-dev      build-essential cmake libboost-all-dev libeigen3-dev
```

### 2.3Â Python Dependencies

```bash
# clone our repo first
git clone https://github.com/yourname/indicwav2vec_finetune.git
cd indicwav2vec_finetune

pip install -r w2v_inference/requirements.txt   # torchaudio, hydra, etc.
pip install packaging soundfile swifter editdistance omegaconf pandas
```

### 2.4Â Fairseq (custom fork used by AI4Bharat)

```bash
git clone https://github.com/AI4Bharat/fairseq.git
cd fairseq
pip install --editable .
cd ..
```

You are now ready to process data.

---

## 3Â Â·Â Dataset Acquisition

### 3.1Â SPRINGâ€‘INX Hindi

* **Hours:** 351.18  
* **Where:** <https://asr.iitm.ac.in/dataset>

Create a file `urls.txt` containing **direct links** to each WAV/ZIP provided by the site.

```
datasets/
â””â”€â”€ urls.txt   # one URL per line
```

---

## 4Â Â·Â Data Preparation (4â€‘stage pipeline)

All helper scripts live in **`data_prep_scripts/`**.

| Stage | Script | What it does | Input â†’ Output |
|-------|--------|--------------|----------------|
| 1 | `dw_util.sh` | Parallel downloader | `urls.txt` â†’ raw WAV/ZIP |
| 2 | `vad.py` | Removes long silences | raw WAV â†’ `*_vad.wav` |
| 3 | `snr_filter.py` | Drops lowâ€‘quality audio (SNRÂ <Â 20â€¯dB) | `*_vad.wav` â†’ clean WAV |
| 4 | `chunking.py` | Splits >15â€¯s files into chunks | clean WAV â†’ â‰¤15â€¯s WAV |

### 4.1Â Run Everything in One Command

```bash
bash data_prep_scripts/process_data.sh datasets/urls.txt      /mnt/hindi_audio 8
```

* **`/mnt/hindi_audio`** will end up like:

```
/mnt/hindi_audio/
â”œâ”€â”€ hindi/
â”‚   â”œâ”€â”€ 000001.wav
â”‚   â”œâ”€â”€ 000002.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ rejected/           # noisy files here
```

> **FAQ:** *Where are transcripts?*  
> Put each languageâ€™s `transcript.txt` next to its WAVs **before** you run stageÂ 4; the chunker keeps filenames intact.

### 4.2Â What If I Only Want VAD?

```bash
python data_prep_scripts/vad.py /mnt/raw /mnt/vad hindi
```

---

## 5Â Â·Â Manifest Creation (Fairseq format)

### 5.1Â Generate Languageâ€‘Wise TSVs

```bash
python data_prep_scripts/lang_wise_manifest_creation.py        /mnt/hindi_audio/hindi        --dest /mnt/hindi_manifest        --ext wav --valid-percent 0.03
```

Youâ€™ll get:

```
/mnt/hindi_manifest/
â”œâ”€â”€ train.tsv   # path 	 duration(ms)
â”œâ”€â”€ train.wrd   # words per line
â”œâ”€â”€ train.ltr   # letters per line
â””â”€â”€ ... (valid / test)
```

### 5.2Â Combine Multiple Languages (optional)

If you ever pretrain, concatenate all `*_valid.tsv` then prepend root path as first line:

```python
import glob, pandas as pd, pathlib, sys
root = pathlib.Path("/mnt/hindi_audio")
dfs = [pd.read_csv(f, sep='\t', names=['path','dur'], skiprows=1)
       for f in glob.glob("*_valid.tsv")]
pd.concat(dfs).to_csv("valid.tsv", sep='\t', header=False, index=False)
```

---

## 6Â Â·Â Model Overview

| Checkpoint | Link | Size |
|------------|------|------|
| **Base**   | [`indicw2v_base_pretrained.pt`](https://indic-asr-public.objectstore.e2enetworks.net/aaai_ckpts/pretrained_models/indicw2v_base_pretrained.pt) | 95â€¯M params |
| **Large**  | `indicw2v_large_pretrained.pt` | 317â€¯M params |

Weâ€™ll fineâ€‘tune **Base**.

---

## 7Â Â·Â Fineâ€‘Tuning

### 7.1Â Minimal Singleâ€‘GPU Command

```bash
fairseq-hydra-train   task.data=/mnt/hindi_manifest   model.w2v_path=indicw2v_base_pretrained.pt   checkpoint.save_dir=/mnt/checkpoints_hindi   +optimization.update_freq='[4]'   optimization.lr=0.00001   dataset.max_tokens=1000000   common.log_interval=50   --config-dir finetune_configs   --config-name ai4b_base
```

### 7.2Â Multiâ€‘Node (Slurm) Template

See `README_SUPER_DETAILED.md` for full `sbatch` line, or reuse:

```bash
sbatch --job-name hindi_ft --gres gpu:4 --nodes 1 --cpus-per-task 16   --wrap "srun fairseq-hydra-train ... "
```

---

## 8Â Â·Â Evaluation

```bash
python w2v_inference/infer.py    /mnt/hindi_manifest    --path /mnt/checkpoints_hindi/checkpoint_best.pt    --task audio_finetuning    --gen-subset test    --results-path results_hindi    --w2l-decoder viterbi
```

`results_hindi/wer` will show perâ€‘sample and average WER.

---

## 9Â Â·Â Common Pitfalls & Fixes

| Symptom | Likely Cause | Fix |
|---------|--------------|-----|
| `RuntimeError: Expected 1D tensor, got 0D` | Empty WAV (0Â samples) | Remove file or reâ€‘run `snr_filter.py` |
| WER stuck at 33â€¯% | LR too high or update_freq=1 | use `0.00001` and `update_freq 4` |
| CUDA OOM | `max_tokens` too big | lower to `500000` |

---

## 10Â Â·Â Training a Language Model (KenLM)

```bash
cd lm_training
bash install_kenlm.sh           # oneâ€‘time build
bash train_lm.sh /mnt/hindi_manifest hindi
```

Produces `lm.binary` and `lexicon.lst` usable with `--w2l-decoder kenlm`.

---

## 11Â Â·Â Advanced: LoRA Fineâ€‘Tuning (coming soon)

We plan to inject Lowâ€‘Rank Adaptation layers into every Transformer block to cut GPU RAM by 60â€¯%. Stay tuned.

---

## 12Â Â·Â Results Snapshot

| Config | max_update | LR | UpdateÂ Freq | BestÂ WER |
|--------|------------|----|-------------|----------|
| C1     | 1.72â€¯M     | 1eâ€‘4 | 1 | 33.71 |
| **C2** | **1.52â€¯M** | **1eâ€‘5** | **4** | **29.93** |

---

## 13Â Â·Â References

See the **reports/** folder for full academic writeâ€‘ups and bibliography.

---

Happy fineâ€‘tuning! If anything is unclear, open an issue or email **Keyur Chaudhari** at _keyur.email@example.com_.
